{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sympy as sy\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDING NANS by Jasleen\n",
    "\n",
    "# percent_missing=X.isnull().sum() * 100 / len(X)\n",
    "# missing_value_df = pd.DataFrame({'column_name': X.columns,\n",
    "#                                  'percent_missing': percent_missing,\n",
    "#                                   'count_missing':X.isnull().sum()})\n",
    "# missing_value_df.sort_values('percent_missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bisection\n",
    "\n",
    "\n",
    "One of the most common algorithms for numerical root-finding is *bisection*.\n",
    "\n",
    "To understand the idea, recall the well-known game where:\n",
    "\n",
    "- Player A thinks of a secret number between 1 and 100  \n",
    "- Player B asks if it’s less than 50  \n",
    "  \n",
    "  - If yes, B asks if it’s less than 25  \n",
    "  - If no, B asks if it’s less than 75  \n",
    "  \n",
    "\n",
    "And so on.\n",
    "\n",
    "This is bisection, a relative of [binary search](https://en.wikipedia.org/wiki/Binary_search_algorithm). It works for all sufficiently well behaved increasing continuous functions with $ f(a) < 0 < f(b) $. \n",
    "\n",
    "Write an implementation of the bisection algorith, `bisect(f, lower, upper, tol)` which, given a function `f`, a lower bound `lower` and an upper bound `upper` finds the point `x` where `f(x) = 0`. The parameter `tol` is a numerical tolerance, you should stop once your step size is smaller than `tol`.\n",
    "\n",
    "\n",
    "Use it to minimize the function:\n",
    "\n",
    "$$\n",
    "f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1 \\tag{2}\n",
    "$$\n",
    "\n",
    "in python: `lambda x: np.sin(4 * (x - 1/4)) + x + x**20 - 1`\n",
    "\n",
    "The value where f(x) = 0 should be around `0.408`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# received help from Javad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 20 x^{19} + 4 \\cos{\\left(4 x - 1.0 \\right)} + 1$"
      ],
      "text/plain": [
       "20*x**19 + 4*cos(4*x - 1.0) + 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sy.symbols(\"x\")\n",
    "sy.diff(sy.sin(4 * (x - 1/4)) + x + x**20 - 1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "#     return 4 * np.cos((4 * x - 1)) + 1 + 20 * x**19\n",
    "    return np.sin(4 * (x - 1/4)) + x + x**20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisect(f, lower, upper, tol):\n",
    "    mid = (upper + lower) / 2\n",
    "    y_left = f(lower)\n",
    "    y_right = f(upper)\n",
    "    y_mid = f(mid)\n",
    "    \n",
    "    if abs(upper - lower) < tol:\n",
    "        return mid\n",
    "    \n",
    "    if y_left * y_right > 0:\n",
    "        print(\"change your lower/upper\")\n",
    "        return\n",
    "    \n",
    "    if y_left * y_mid > 0: \n",
    "        return bisect(f, mid, upper, tol)\n",
    "    else:\n",
    "        return bisect(f, lower, mid, tol)\n",
    "\n",
    "#     SOLUTION:\n",
    "#     while upper - lower > tol:\n",
    "#         mid = 0.5 * (upper + lower)\n",
    "#         if f(mid) > 0:   # root is between lower and middle\n",
    "#             lower, upper = lower, mid\n",
    "#         else:            # root is between middle and upper\n",
    "#             lower, upper = mid, upper\n",
    "            \n",
    "#     return 0.5 * (upper + lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40869140625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min = bisect(f, 0, 1, .001)\n",
    "x_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 (stretch) Recursive Bisect\n",
    "\n",
    "Write a recursive version of the bisection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Movies Regression\n",
    "\n",
    "Write the best linear regression model you can on the [Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset?select=ratings.csv) to predict the profitability of a movie (revenue - budget). Maintain the interpretability of the model.\n",
    "\n",
    "Few notes:\n",
    "\n",
    "1. Clean your data! Movies where the budget or revenue are invalid should be thrown out\n",
    "\n",
    "2. Be creative with feature engineering. You can include processing to one-hot encode the type of movie, etc.\n",
    "\n",
    "3. The model should be useful for someone **who is thinking about making a movie**. So features like the popularity can't be used. You could, however, use the ratings to figure out if making \"good\" or \"oscar bait\" movies is a profitable strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPi9xcx3mywk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rando\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/movies_metadata.csv\")\n",
    "df = df.dropna(subset = [\"budget\", \"revenue\", \"runtime\"])\n",
    "df.budget = df.budget.astype(int)\n",
    "df.revenue = df.revenue.astype(int)\n",
    "df = df[df.budget != 0]\n",
    "df = df[df.revenue != 0]\n",
    "df = df.drop(columns = [\"id\", \"imdb_id\", \"overview\", \"poster_path\", \"homepage\", \"popularity\", \"vote_average\", \"vote_count\",\n",
    "                       \"tagline\", \"title\", \"original_title\", \"video\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Received help from Javad\n",
    "\n",
    "X = df.copy()\n",
    "\n",
    "X.belongs_to_collection = X.belongs_to_collection.fillna(\"{'name': 'No collection'}\")\n",
    "X.belongs_to_collection = X.belongs_to_collection.apply(eval)\n",
    "X.belongs_to_collection = X.belongs_to_collection.apply(lambda x: x[\"name\"])\n",
    "\n",
    "X.release_date = pd.to_datetime(X.release_date)\n",
    "X[\"modern\"] = (X.release_date > \"2000-01-01\").astype(int)\n",
    "\n",
    "# Keeping only the first one in each, assuming it is the primary (based on very loose testing)\n",
    "X.genres = X.genres.apply(eval)\n",
    "X.genres = X.genres.apply(lambda x : x[0][\"name\"] if len(x) else \"None\")\n",
    "\n",
    "X.production_companies = X.production_companies.apply(eval)\n",
    "X.production_companies = X.production_companies.apply(lambda x : x[0][\"name\"] if len(x) else \"None\")\n",
    "\n",
    "X.production_countries = X.production_countries.apply(eval)\n",
    "X.production_countries = X.production_countries.apply(lambda x : x[0][\"name\"] if len(x) else \"None\")\n",
    "\n",
    "# creating a binary column: \n",
    "X[\"has_collection\"] = (X.belongs_to_collection != \"No collection\").astype(int) # has collection or not\n",
    "X[\"country\"] = (X.production_countries == \"United States of America\").astype(int) # produced in the US or not\n",
    "\n",
    "top10 = X.production_companies.value_counts()\n",
    "top10 = top10[:12]\n",
    "top10 = top10.index\n",
    "top10 = top10.drop(\"None\")\n",
    "\n",
    "X[\"production\"] = X.production_companies.apply(lambda x: (x in top10)) # top10 production companies or not\n",
    "X.production = X.production.astype(int) # cannot do .astype(int) in apply lambda for some reason\n",
    "\n",
    "X[\"language\"] = X.original_language.apply(lambda x: (x == \"en\")) # if original language was enlgish or not\n",
    "X.language = X.language.astype(int) # same reason as above\n",
    "\n",
    "X[\"for_adults\"] = X.adult.apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "X = X.join(pd.get_dummies(X.genres, drop_first = True))\n",
    "X = X.join(pd.get_dummies(X.status, drop_first = True))\n",
    "\n",
    "# dropping columns that are no longer needed\n",
    "X = X.drop(columns = [\"belongs_to_collection\", \"production_countries\", \"production_companies\", \"genres\", \"spoken_languages\",\n",
    "                     \"adult\", \"original_language\", \"status\", \"revenue\", \"release_date\", \"Rumored\", \"Released\", \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>modern</th>\n",
       "      <th>has_collection</th>\n",
       "      <th>country</th>\n",
       "      <th>production</th>\n",
       "      <th>language</th>\n",
       "      <th>for_adults</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16000000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60000000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  runtime  modern  has_collection  country  production  language  \\\n",
       "0  30000000     81.0       0               1        1           0         1   \n",
       "1  65000000    104.0       0               0        1           0         1   \n",
       "3  16000000    127.0       0               0        1           1         1   \n",
       "5  60000000    170.0       0               0        1           0         1   \n",
       "8  35000000    106.0       0               0        1           1         1   \n",
       "\n",
       "   for_adults  Adventure  Animation  ...  History  Horror  Music  Mystery  \\\n",
       "0           0          0          1  ...        0       0      0        0   \n",
       "1           0          1          0  ...        0       0      0        0   \n",
       "3           0          0          0  ...        0       0      0        0   \n",
       "5           0          0          0  ...        0       0      0        0   \n",
       "8           0          0          0  ...        0       0      0        0   \n",
       "\n",
       "   Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0        0                0         0         0    0        0  \n",
       "1        0                0         0         0    0        0  \n",
       "3        0                0         0         0    0        0  \n",
       "5        0                0         0         0    0        0  \n",
       "8        0                0         0         0    0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X, has_constant = 'add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>revenue</td>     <th>  R-squared:         </th>  <td>   0.550</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.549</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   655.4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Jan 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:50:09</td>     <th>  Log-Likelihood:    </th> <td>-1.0728e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5380</td>      <th>  AIC:               </th>  <td>2.146e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5369</td>      <th>  BIC:               </th>  <td>2.147e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>-1.017e+08</td> <td> 8.86e+06</td> <td>  -11.478</td> <td> 0.000</td> <td>-1.19e+08</td> <td>-8.43e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>budget</th>         <td>    2.6004</td> <td>    0.042</td> <td>   62.214</td> <td> 0.000</td> <td>    2.518</td> <td>    2.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>runtime</th>        <td> 6.684e+05</td> <td> 7.46e+04</td> <td>    8.955</td> <td> 0.000</td> <td> 5.22e+05</td> <td> 8.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_collection</th> <td> 8.057e+07</td> <td> 3.79e+06</td> <td>   21.268</td> <td> 0.000</td> <td> 7.31e+07</td> <td>  8.8e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>country</th>        <td> 1.224e+07</td> <td> 3.21e+06</td> <td>    3.810</td> <td> 0.000</td> <td> 5.94e+06</td> <td> 1.85e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Adventure</th>      <td> 1.973e+07</td> <td> 6.04e+06</td> <td>    3.269</td> <td> 0.001</td> <td>  7.9e+06</td> <td> 3.16e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Animation</th>      <td> 6.987e+07</td> <td> 9.71e+06</td> <td>    7.199</td> <td> 0.000</td> <td> 5.08e+07</td> <td> 8.89e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Comedy</th>         <td> 1.697e+07</td> <td> 4.19e+06</td> <td>    4.045</td> <td> 0.000</td> <td> 8.74e+06</td> <td> 2.52e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Drama</th>          <td>  9.65e+06</td> <td> 4.01e+06</td> <td>    2.408</td> <td> 0.016</td> <td> 1.79e+06</td> <td> 1.75e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Family</th>         <td> 7.929e+07</td> <td> 1.52e+07</td> <td>    5.214</td> <td> 0.000</td> <td> 4.95e+07</td> <td> 1.09e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romance</th>        <td> 3.008e+07</td> <td> 1.04e+07</td> <td>    2.898</td> <td> 0.004</td> <td> 9.73e+06</td> <td> 5.04e+07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2531.730</td> <th>  Durbin-Watson:     </th>  <td>   1.937</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2277941.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.749</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>103.795</td> <th>  Cond. No.          </th>  <td>5.15e+08</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.15e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                revenue   R-squared:                       0.550\n",
       "Model:                            OLS   Adj. R-squared:                  0.549\n",
       "Method:                 Least Squares   F-statistic:                     655.4\n",
       "Date:                Sat, 30 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        12:50:09   Log-Likelihood:            -1.0728e+05\n",
       "No. Observations:                5380   AIC:                         2.146e+05\n",
       "Df Residuals:                    5369   BIC:                         2.147e+05\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const          -1.017e+08   8.86e+06    -11.478      0.000   -1.19e+08   -8.43e+07\n",
       "budget             2.6004      0.042     62.214      0.000       2.518       2.682\n",
       "runtime         6.684e+05   7.46e+04      8.955      0.000    5.22e+05    8.15e+05\n",
       "has_collection  8.057e+07   3.79e+06     21.268      0.000    7.31e+07     8.8e+07\n",
       "country         1.224e+07   3.21e+06      3.810      0.000    5.94e+06    1.85e+07\n",
       "Adventure       1.973e+07   6.04e+06      3.269      0.001     7.9e+06    3.16e+07\n",
       "Animation       6.987e+07   9.71e+06      7.199      0.000    5.08e+07    8.89e+07\n",
       "Comedy          1.697e+07   4.19e+06      4.045      0.000    8.74e+06    2.52e+07\n",
       "Drama            9.65e+06   4.01e+06      2.408      0.016    1.79e+06    1.75e+07\n",
       "Family          7.929e+07   1.52e+07      5.214      0.000    4.95e+07    1.09e+08\n",
       "Romance         3.008e+07   1.04e+07      2.898      0.004    9.73e+06    5.04e+07\n",
       "==============================================================================\n",
       "Omnibus:                     2531.730   Durbin-Watson:                   1.937\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2277941.765\n",
       "Skew:                          -0.749   Prob(JB):                         0.00\n",
       "Kurtosis:                     103.795   Cond. No.                     5.15e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.15e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.revenue\n",
    "\n",
    "# revisions: \n",
    "X = X.drop(columns = [\"modern\", \"production\", \"language\", \"for_adults\"]) \n",
    "X = X.drop(columns = [\"Crime\",\"Fantasy\", \"Horror\", \"Mystery\", \"Science Fiction\", \"Thriller\", \"War\", \"Western\", \"Documentary\",\n",
    "                        \"Foreign\", \"History\", \"Music\", \"TV Movie\"]) \n",
    "\n",
    "est = sm.OLS(y, X).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Movies Manual Regression\n",
    "\n",
    "Use your `X` and `y` matrix from 2.1 to calculate the linear regression yourself using the normal equation $(X^T X)^{-1}X^Ty$.\n",
    "\n",
    "Verify that the coefficients are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = [\"const\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.659555e+00\n",
       "1   -1.220905e+05\n",
       "2    7.293247e+07\n",
       "3   -1.104919e+05\n",
       "4    1.501562e+07\n",
       "5    4.710976e+07\n",
       "6    5.548095e+06\n",
       "7    7.675802e+06\n",
       "8    6.153250e+07\n",
       "9    2.234696e+07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X.T @ X) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient for runtime is **VERY** off, the rest are close but not an identical match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Movies gradient descent regression\n",
    "\n",
    "Use your `X` and `y` matrix from 2.1 to calculate the linear regression yourself using **gradient descent**. \n",
    "\n",
    "Hint: use `scipy.optimize` and remember we're finding the $\\beta$ that minimizes the squared loss function of linear regression: $f(\\beta) = (\\beta X - y)^2$. This will look like part 3 of this lecture.\n",
    "\n",
    "Verify your coefficients are similar to the ones in 2.1 and 2.2. They won't necessarily be exactly the same, but should be roughly similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squaredLoss(betas, y, x):\n",
    "    result = 0\n",
    "    \n",
    "    for i in range(0, len(y)):\n",
    "        xb = np.dot(x[i], betas)\n",
    "        llf = (xb - y[i])  ** 2\n",
    "        result += llf\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhat = np.zeros(len(X[0]))\n",
    "probit_est = opt.minimize(squaredLoss, bhat, args=(y,X), method='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.89307841, -1.55767358,  0.08871133,  0.54729502, -0.71134332,\n",
       "       -0.00400039, -0.60025477,  1.41786171, -0.65935014, -0.39338817])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probit_est['x']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIPzivigAhB3FeR6Q96N8T",
   "collapsed_sections": [],
   "name": "Workshop: Maximum likelihood.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
